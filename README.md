# Подготовка данных LibriSpeech

Графический интерфейс `main.py` объединяет устаревшие сценарии подготовки данных в единый рабочий процесс. Приложение собирает массивы для обучения CTC-модели и при необходимости формирует дополнительные последовательности фонем.

## Зависимости

- Python 3.10 или новее
- Системные модули `tkinter` (ставится вместе с большинством сборок Python)
- Локальные модули проекта: `preparation_data.py`, `file_utility.py`
- Внешние пакеты (установка через `pip install -r requirements.txt`):
	- `numpy`
	- `matplotlib` — для визуализации мел-спектрограмм
	- `g2p_en` — для фонемной конвертации (опционально)

## Запуск

```bash
python main.py
```

Откроется окно с основными параметрами:

- **Корневая папка LibriSpeech** — директория, содержащая структуру датасета (`train-clean-100`, `test-other` и т.д.).
- **Папка для сохранения результата** — куда будут записаны `x_data.npy`, `y_labels.npy`, `x_input_length.npy`, `y_label_length.npy`.
- **Размер окна (временные шаги)** — максимальное количество кадров спектрограммы. Если встречаются более длинные записи, увеличьте значение.
- **Максимальная длина метки** — ограничение длины токенизированного текста.
- **Сохранить последовательности фонем** — опция запуска дополнительной обработки. При активации появится поле **Максимальная длина фонем**.
- **Перемешать примеры** — случайно перемешивает порядок обработанных примеров перед сохранением `.npy`.
- **Просмотр подготовленных данных** — нижняя часть окна. После окончания обработки (или вручную, указав готовую папку) можно выбрать индекс и посмотреть мел-спектрограмму конкретного примера.

Нажмите **«Запустить обработку»**, чтобы создать набор данных. Журнал выполнения отображает ход работы и список сохранённых файлов. Обработка выполняется в отдельном потоке и параллельно задействует все доступные CPU, поэтому окно остаётся отзывчивым.

## Структура выходных файлов

- `x_data.npy` — спектрограммы в формате `float32`, выровненные по выбранному окну.
- `y_labels.npy` — целочисленные метки (токены), заполненные нулями до максимальной длины.
- `x_input_length.npy` — фактическая длина каждой спектрограммы.
- `y_label_length.npy` — фактическая длина каждой последовательности токенов.
- `xy_sample_names.npy` — исходные идентификаторы аудиофайлов (например, `19-198-0001`).
- При включённой опции фонем: `y_labels_phoneme.npy` и `y_label_length_phoneme.npy` с соответствующими ограничениями.

## Дополнительные замечания

- Скрипт предполагает, что функции `process_audio_and_text_nornalize`, `detokenize_text_with_space_train`, `list_third_level_directories`, `get_txt_files` и `extract_pairs_from_file` доступны и корректно настроены.
- Для больших подмножеств LibriSpeech требуется значительное свободное место на диске. Файлы `.npy` создаются в режиме `memmap`, что уменьшает потребление оперативной памяти.
- При завершении подготовки данные автоматически подгружаются во встроенный просмотрщик. При необходимости можно загрузить любую другую директорию вручную.
- При возникновении ошибки о превышении длины спектрограммы или метки увеличьте соответствующие параметры в интерфейсе.
- Файл `metadata.json` теперь содержит поле `"shuffle"`, показывающее, были ли примеры перемешаны при подготовке.


python -m venv venv

venv\Scripts\Activate.ps1
venv\Scripts\activate.bat
deactivate


python -m nltk.downloader averaged_perceptron_tagger cmudict